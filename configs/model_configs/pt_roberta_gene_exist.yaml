model:
  class: RobertaGEForMaskedLM
  n_attention_heads: 2
  n_hidden_layers: 2
  hidden_size: 256
tokenizer:
  use_pretrained: False
  class: RobertaTokenizer
  columns_for_vocab:
    - AMR_genotypes_core