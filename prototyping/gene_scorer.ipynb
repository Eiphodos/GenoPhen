{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-23T15:29:19.337391021Z",
     "start_time": "2023-11-23T15:29:19.323276648Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "outputs": [],
   "source": [
    "genes = [0, 1, 2, 3]\n",
    "ab = [0, 1, 2, 3]\n",
    "\n",
    "data_old = [{'genes': [1, 0, 0, 0], 'res': [0, 0, 0, 0]},\n",
    "        {'genes': [0, 1, 0, 0], 'res': [0, 1, 0, 0]},\n",
    "        {'genes': [0, 0, 1, 0], 'res': [0, 0, 0, 0]},\n",
    "        {'genes': [0, 0, 0, 1], 'res': [0, 0, 0, 0]},\n",
    "        {'genes': [1, 1, 0, 0], 'res': [0, 1, 0, 0]},\n",
    "        {'genes': [1, 0, 1, 0], 'res': [0, 0, 0, 0]},\n",
    "        {'genes': [1, 0, 0, 1], 'res': [0, 0, 0, 0]},\n",
    "        {'genes': [0, 1, 1, 0], 'res': [0, 1, 1, 0]},\n",
    "        {'genes': [0, 1, 0, 1], 'res': [0, 1, 0, 1]},\n",
    "        {'genes': [0, 0, 1, 1], 'res': [0, 0, 0, 0]},\n",
    "        {'genes': [1, 0, 0, 0], 'res': [0, 0, 0, 0]}, \n",
    "        {'genes': [0, 0, 1, 0], 'res': [0, 0, 0, 0]},\n",
    "        {'genes': [0, 0, 0, 1], 'res': [0, 0, 0, 0]},\n",
    "        {'genes': [0, 1, 0, 0], 'res': [0, 1, 0, 0]},\n",
    "        {'genes': [0, 1, 0, 0], 'res': [0, 1, 0, 0]},\n",
    "        {'genes': [0, 1, 0, 0], 'res': [0, 1, 0, 0]},\n",
    "        ]\n",
    "\n",
    "\n",
    "data = [{'genes': [0, 0, 0, 0], 'res': [0, 0, 0, 0]},\n",
    "        {'genes': [1, 0, 0, 0], 'res': [0, 0, 0, 0]},\n",
    "        {'genes': [0, 1, 0, 0], 'res': [0, 1, 0, 0]},\n",
    "        {'genes': [0, 0, 1, 0], 'res': [0, 0, 0, 0]},\n",
    "        {'genes': [0, 0, 0, 1], 'res': [0, 0, 0, 0]},\n",
    "        {'genes': [1, 1, 0, 0], 'res': [0, 1, 0, 0]},\n",
    "        {'genes': [1, 0, 1, 0], 'res': [0, 0, 0, 0]},\n",
    "        {'genes': [1, 0, 0, 1], 'res': [0, 0, 0, 0]},\n",
    "        {'genes': [0, 1, 1, 0], 'res': [0, 1, 0, 0]},\n",
    "        {'genes': [0, 1, 0, 1], 'res': [0, 1, 0, 0]},\n",
    "        {'genes': [0, 0, 1, 1], 'res': [0, 0, 0, 0]},\n",
    "        {'genes': [1, 0, 1, 1], 'res': [0, 0, 0, 0]},\n",
    "        {'genes': [1, 1, 0, 1], 'res': [0, 1, 0, 0]},\n",
    "        {'genes': [1, 1, 1, 0], 'res': [0, 1, 0, 0]},\n",
    "        {'genes': [0, 1, 1, 1], 'res': [0, 1, 0, 0]},\n",
    "        {'genes': [1, 1, 1, 1], 'res': [0, 1, 0, 0]},\n",
    "        ]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T15:29:19.373506625Z",
     "start_time": "2023-11-23T15:29:19.329759569Z"
    }
   },
   "id": "d99c94cc05e6a51"
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "outputs": [],
   "source": [
    "class GabDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, data):\n",
    "                self.data = data\n",
    "\n",
    "\n",
    "        def __len__(self):\n",
    "                return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "                d = self.data[idx]\n",
    "                return torch.IntTensor(d['genes']), torch.LongTensor(d['res'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T15:29:19.373644051Z",
     "start_time": "2023-11-23T15:29:19.373421601Z"
    }
   },
   "id": "d4ed7beedf43e9c9"
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "outputs": [],
   "source": [
    "class GabModel(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "                super().__init__()\n",
    "                self.genes = torch.IntTensor([0, 1, 2, 3]).to('cuda')\n",
    "                self.hidden_dim = 64\n",
    "                self.n_known = 1\n",
    "                self.g_emb = torch.nn.Embedding(5, self.hidden_dim, padding_idx=4)\n",
    "                self.g2_emb = torch.nn.Embedding(5, self.hidden_dim, padding_idx=4)\n",
    "                self.exist_emb = torch.nn.Embedding(3, self.hidden_dim, padding_idx=2)\n",
    "                self.scorer = torch.nn.Sequential(torch.nn.Linear(self.hidden_dim, self.hidden_dim // 2),\n",
    "                                                  torch.nn.ReLU(),\n",
    "                                                  torch.nn.Linear(self.hidden_dim // 2, 1))\n",
    "                self.reverse_scorer = torch.nn.Sequential(torch.nn.Linear(1, self.hidden_dim // 2),\n",
    "                                                          torch.nn.ReLU(),\n",
    "                                                          torch.nn.Linear(self.hidden_dim // 2, self.hidden_dim))\n",
    "                self.layers = torch.nn.Sequential(torch.nn.Linear(self.hidden_dim, self.hidden_dim * 2),\n",
    "                                                  torch.nn.ReLU(),\n",
    "                                                  torch.nn.Linear(self.hidden_dim * 2, self.hidden_dim * 4),\n",
    "                                                  torch.nn.ReLU(),\n",
    "                                                  torch.nn.Linear(self.hidden_dim * 4, self.hidden_dim * 8),\n",
    "                                                  torch.nn.ReLU())\n",
    "                self.head1 = torch.nn.Linear(self.hidden_dim * 8, 2)\n",
    "                self.head2 = torch.nn.Linear(self.hidden_dim * 8, 2)\n",
    "                self.head3 = torch.nn.Linear(self.hidden_dim * 8, 2)\n",
    "                self.head4 = torch.nn.Linear(self.hidden_dim * 8, 2)\n",
    "        \n",
    "        def forward(self, x):\n",
    "                b = x.shape[0]\n",
    "                g = self.genes.repeat(b, 1)\n",
    "                gene_emb = self.g_emb(self.genes)\n",
    "                gene_scores = self.scorer(gene_emb)\n",
    "                gene_scores = torch.nn.functional.softmax(gene_scores, dim=0)\n",
    "                #print(\"Gene scores are: {}\".format(gene_scores.view(-1)))\n",
    "                scores, i = torch.topk(gene_scores.view(-1), self.n_known, dim=0)\n",
    "                out_i = i\n",
    "                #print(\"Selected genes are: {}\".format(i))\n",
    "                scores_comp = 0\n",
    "                if self.n_known < 4:\n",
    "                        random_gene = torch.multinomial(torch.Tensor([0 if g in i else 1 for g in genes]).to('cuda'), 1)\n",
    "                        #print(\"Random gene is: {}\".format(random_gene))\n",
    "                        i = torch.cat([i, random_gene])\n",
    "                        g_comp = torch.Tensor([1 if g in i else 0 for g in genes]).to('cuda')\n",
    "                        i_comp = torch.Tensor([j for j in range(4) if j not in i]).to('cuda').int()\n",
    "                        scores_comp = gene_scores.view(-1)[i_comp]\n",
    "                        scores = torch.cat([scores, gene_scores.view(-1)[random_gene]])\n",
    "                        #scores_exclude = gene_scores.view(-1) #* g_comp\n",
    "\n",
    "                sel_genes = g[:,i]\n",
    "                sel_known = x[:,i]\n",
    "                sel_g_emb = self.g2_emb(sel_genes)\n",
    "                sel_exist_emb = self.exist_emb(sel_known)\n",
    "                scores_pow = torch.pow(scores.unsqueeze(0).unsqueeze(2), 2)\n",
    "                sel_score_emb = self.reverse_scorer(scores_pow)\n",
    "                sel_emb = sel_g_emb + sel_exist_emb + sel_score_emb\n",
    "                \n",
    "                out_emb = self.layers(sel_emb)\n",
    "                \n",
    "                out_mean = torch.mean(out_emb, dim=1)\n",
    "                \n",
    "                \n",
    "                pred_1 = self.head1(out_mean)\n",
    "                pred_2 = self.head2(out_mean)\n",
    "                pred_3 = self.head3(out_mean)\n",
    "                pred_4 = self.head4(out_mean)\n",
    "                \n",
    "                return pred_1, pred_2, pred_3, pred_4, scores, out_i, scores_comp, gene_scores.view(-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T15:29:19.373674955Z",
     "start_time": "2023-11-23T15:29:19.373476113Z"
    }
   },
   "id": "43443cbd22ac857e"
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "outputs": [],
   "source": [
    "def compute_loss(pred_1, pred_2, pred_3, pred_4, labels_1, labels_2, labels_3, labels_4, scores, scores_comp):\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        loss_1 = loss_fn(pred_1, labels_1)\n",
    "        loss_2 = loss_fn(pred_2, labels_2)\n",
    "        loss_3 = loss_fn(pred_3, labels_3)\n",
    "        loss_4 = loss_fn(pred_4, labels_4)\n",
    "        \n",
    "        total_pred_loss = (loss_1 + loss_2 + loss_3 + loss_4).mean()\n",
    "        #print(\"Mean CE loss: {}\".format(total_pred_loss))\n",
    "        total_loss = total_pred_loss\n",
    "        #total_loss = total_pred_loss\n",
    "        return total_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T15:29:19.373695908Z",
     "start_time": "2023-11-23T15:29:19.373499290Z"
    }
   },
   "id": "d781482f38c729c2"
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 0 --- Accuracy AB 1: 0.4375 ---\n",
      "--- Epoch 0 --- Mean Accuracy: 0.4375 ---\n",
      "--- Epoch 1 --- Accuracy AB 1: 0.625 ---\n",
      "--- Epoch 1 --- Mean Accuracy: 0.625 ---\n",
      "--- Epoch 2 --- Accuracy AB 1: 0.75 ---\n",
      "--- Epoch 2 --- Mean Accuracy: 0.75 ---\n",
      "--- Epoch 3 --- Accuracy AB 1: 0.625 ---\n",
      "--- Epoch 3 --- Mean Accuracy: 0.65625 ---\n",
      "--- Epoch 4 --- Accuracy AB 1: 0.75 ---\n",
      "--- Epoch 4 --- Mean Accuracy: 0.609375 ---\n",
      "--- Epoch 5 --- Accuracy AB 1: 0.3125 ---\n",
      "--- Epoch 5 --- Mean Accuracy: 0.671875 ---\n",
      "--- Epoch 6 --- Accuracy AB 1: 0.5 ---\n",
      "--- Epoch 6 --- Mean Accuracy: 0.640625 ---\n",
      "--- Epoch 7 --- Accuracy AB 1: 0.5625 ---\n",
      "--- Epoch 7 --- Mean Accuracy: 0.671875 ---\n",
      "--- Epoch 8 --- Accuracy AB 1: 0.4375 ---\n",
      "--- Epoch 8 --- Mean Accuracy: 0.703125 ---\n",
      "--- Epoch 9 --- Accuracy AB 1: 0.6875 ---\n",
      "--- Epoch 9 --- Mean Accuracy: 0.734375 ---\n",
      "--- Epoch 10 --- Accuracy AB 1: 0.625 ---\n",
      "--- Epoch 10 --- Mean Accuracy: 0.75 ---\n",
      "--- Epoch 11 --- Accuracy AB 1: 0.625 ---\n",
      "--- Epoch 11 --- Mean Accuracy: 0.71875 ---\n",
      "--- Epoch 12 --- Accuracy AB 1: 0.5625 ---\n",
      "--- Epoch 12 --- Mean Accuracy: 0.71875 ---\n",
      "--- Epoch 13 --- Accuracy AB 1: 0.625 ---\n",
      "--- Epoch 13 --- Mean Accuracy: 0.703125 ---\n",
      "--- Epoch 14 --- Accuracy AB 1: 0.625 ---\n",
      "--- Epoch 14 --- Mean Accuracy: 0.71875 ---\n",
      "--- Epoch 15 --- Accuracy AB 1: 0.875 ---\n",
      "--- Epoch 15 --- Mean Accuracy: 0.71875 ---\n",
      "--- Epoch 16 --- Accuracy AB 1: 0.5625 ---\n",
      "--- Epoch 16 --- Mean Accuracy: 0.703125 ---\n",
      "--- Epoch 17 --- Accuracy AB 1: 0.75 ---\n",
      "--- Epoch 17 --- Mean Accuracy: 0.734375 ---\n",
      "--- Epoch 18 --- Accuracy AB 1: 0.8125 ---\n",
      "--- Epoch 18 --- Mean Accuracy: 0.75 ---\n",
      "--- Epoch 19 --- Accuracy AB 1: 0.5 ---\n",
      "--- Epoch 19 --- Mean Accuracy: 0.734375 ---\n",
      "--- Epoch 20 --- Accuracy AB 1: 0.625 ---\n",
      "--- Epoch 20 --- Mean Accuracy: 0.734375 ---\n",
      "--- Epoch 21 --- Accuracy AB 1: 0.5625 ---\n",
      "--- Epoch 21 --- Mean Accuracy: 0.703125 ---\n",
      "--- Epoch 22 --- Accuracy AB 1: 0.8125 ---\n",
      "--- Epoch 22 --- Mean Accuracy: 0.734375 ---\n",
      "--- Epoch 23 --- Accuracy AB 1: 0.75 ---\n",
      "--- Epoch 23 --- Mean Accuracy: 0.859375 ---\n",
      "--- Epoch 24 --- Accuracy AB 1: 0.4375 ---\n",
      "--- Epoch 24 --- Mean Accuracy: 0.6875 ---\n",
      "--- Epoch 25 --- Accuracy AB 1: 0.6875 ---\n",
      "--- Epoch 25 --- Mean Accuracy: 0.75 ---\n",
      "--- Epoch 26 --- Accuracy AB 1: 0.6875 ---\n",
      "--- Epoch 26 --- Mean Accuracy: 0.75 ---\n",
      "--- Epoch 27 --- Accuracy AB 1: 0.6875 ---\n",
      "--- Epoch 27 --- Mean Accuracy: 0.765625 ---\n",
      "--- Epoch 28 --- Accuracy AB 1: 0.5625 ---\n",
      "--- Epoch 28 --- Mean Accuracy: 0.703125 ---\n",
      "--- Epoch 29 --- Accuracy AB 1: 0.625 ---\n",
      "--- Epoch 29 --- Mean Accuracy: 0.765625 ---\n",
      "--- Epoch 30 --- Accuracy AB 1: 0.6875 ---\n",
      "--- Epoch 30 --- Mean Accuracy: 0.765625 ---\n",
      "--- Epoch 31 --- Accuracy AB 1: 0.625 ---\n",
      "--- Epoch 31 --- Mean Accuracy: 0.703125 ---\n",
      "--- Epoch 32 --- Accuracy AB 1: 0.4375 ---\n",
      "--- Epoch 32 --- Mean Accuracy: 0.703125 ---\n",
      "--- Epoch 33 --- Accuracy AB 1: 0.625 ---\n",
      "--- Epoch 33 --- Mean Accuracy: 0.734375 ---\n",
      "--- Epoch 34 --- Accuracy AB 1: 0.6875 ---\n",
      "--- Epoch 34 --- Mean Accuracy: 0.703125 ---\n",
      "--- Epoch 35 --- Accuracy AB 1: 0.75 ---\n",
      "--- Epoch 35 --- Mean Accuracy: 0.75 ---\n",
      "--- Epoch 36 --- Accuracy AB 1: 0.5625 ---\n",
      "--- Epoch 36 --- Mean Accuracy: 0.71875 ---\n",
      "--- Epoch 37 --- Accuracy AB 1: 0.5 ---\n",
      "--- Epoch 37 --- Mean Accuracy: 0.734375 ---\n",
      "--- Epoch 38 --- Accuracy AB 1: 0.6875 ---\n",
      "--- Epoch 38 --- Mean Accuracy: 0.671875 ---\n",
      "--- Epoch 39 --- Accuracy AB 1: 0.625 ---\n",
      "--- Epoch 39 --- Mean Accuracy: 0.734375 ---\n",
      "--- Epoch 40 --- Accuracy AB 1: 0.625 ---\n",
      "--- Epoch 40 --- Mean Accuracy: 0.6875 ---\n",
      "--- Epoch 41 --- Accuracy AB 1: 0.6875 ---\n",
      "--- Epoch 41 --- Mean Accuracy: 0.765625 ---\n",
      "--- Epoch 42 --- Accuracy AB 1: 0.625 ---\n",
      "--- Epoch 42 --- Mean Accuracy: 0.734375 ---\n",
      "--- Epoch 43 --- Accuracy AB 1: 0.8125 ---\n",
      "--- Epoch 43 --- Mean Accuracy: 0.8125 ---\n",
      "--- Epoch 44 --- Accuracy AB 1: 0.75 ---\n",
      "--- Epoch 44 --- Mean Accuracy: 0.765625 ---\n",
      "--- Epoch 45 --- Accuracy AB 1: 0.6875 ---\n",
      "--- Epoch 45 --- Mean Accuracy: 0.75 ---\n",
      "--- Epoch 46 --- Accuracy AB 1: 0.8125 ---\n",
      "--- Epoch 46 --- Mean Accuracy: 0.703125 ---\n",
      "--- Epoch 47 --- Accuracy AB 1: 0.8125 ---\n",
      "--- Epoch 47 --- Mean Accuracy: 0.859375 ---\n",
      "--- Epoch 48 --- Accuracy AB 1: 0.6875 ---\n",
      "--- Epoch 48 --- Mean Accuracy: 0.78125 ---\n",
      "--- Epoch 49 --- Accuracy AB 1: 0.4375 ---\n",
      "--- Epoch 49 --- Mean Accuracy: 0.65625 ---\n",
      "Final Loss is: 1.6807496547698975\n",
      "Final Selected genes are: tensor([2], device='cuda:0')\n",
      "Final Selected gene scores are: tensor([0.8066, 0.0452], device='cuda:0', grad_fn=<CatBackward0>)\n",
      "Final Excluded gene scores scores are: tensor([0.0866, 0.0616], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "Final All gene scores scores are: tensor([0.0866, 0.0452, 0.8066, 0.0616], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dataset = GabDataset(data)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=1)\n",
    "\n",
    "model = GabModel()\n",
    "model.to('cuda')\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                                  lr=1e-3,\n",
    "                                  weight_decay=1e-4)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "print_every_n_epochs = 500\n",
    "\n",
    "for e in range(epochs):\n",
    "        n_correct_ab_1 = 0\n",
    "        n_ab_1 = 0\n",
    "        n_correct_ab_2 = 0\n",
    "        n_ab_2 = 0\n",
    "        n_correct_ab_3 = 0\n",
    "        n_ab_3 = 0\n",
    "        n_correct_ab_4 = 0\n",
    "        n_ab_4 = 0\n",
    "        for d, l in data_loader:\n",
    "                d = d.to('cuda')\n",
    "                l = d.to('cuda').long()\n",
    "                labels_1 = l[:,0]\n",
    "                labels_2 = l[:,1]\n",
    "                labels_3 = l[:,2]\n",
    "                labels_4 = l[:,3]\n",
    "                pred_1, pred_2, pred_3, pred_4, scores, out_i, scores_comp, all_scores = model(d)\n",
    "                loss = compute_loss(pred_1, pred_2, pred_3, pred_4, labels_1, labels_2, labels_3, labels_4, scores, scores_comp)\n",
    "                if (e + 1) % print_every_n_epochs == 0:\n",
    "                        print(\"Loss is: {}\".format(loss))\n",
    "                        print(\"Selected genes are: {}\".format(out_i))\n",
    "                        print(\"Selected gene scores are: {}\".format(scores))\n",
    "                        print(\"Excluded gene scores scores are: {}\".format(scores_comp))\n",
    "                        print(\"All gene scores scores are: {}\".format(all_scores))\n",
    "                hard_pred_1 = torch.argmax(pred_1, dim=1)\n",
    "                hard_pred_2 = torch.argmax(pred_2, dim=1)\n",
    "                hard_pred_3 = torch.argmax(pred_3, dim=1)\n",
    "                hard_pred_4 = torch.argmax(pred_4, dim=1)\n",
    "                \n",
    "                n_correct_ab_1 += (hard_pred_1 == labels_1).sum()\n",
    "                n_ab_1 += 1\n",
    "                n_correct_ab_2 += (hard_pred_2 == labels_2).sum()\n",
    "                n_ab_2 += 1\n",
    "                n_correct_ab_3 += (hard_pred_3 == labels_3).sum()\n",
    "                n_ab_3 += 1\n",
    "                n_correct_ab_4 += (hard_pred_4 == labels_4).sum()\n",
    "                n_ab_4 += 1\n",
    "                \n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "        acc_ab_1 = n_correct_ab_1 / n_ab_1\n",
    "        acc_ab_2 = n_correct_ab_2 / n_ab_2\n",
    "        acc_ab_3 = n_correct_ab_3 / n_ab_3\n",
    "        acc_ab_4 = n_correct_ab_4 / n_ab_4\n",
    "        mean_acc = (acc_ab_1 + acc_ab_2 + acc_ab_3 + acc_ab_4) / 4\n",
    "        #print(\"--- Epoch {} --- Accuracy AB 0: {} ---\".format(e, acc_ab_1))\n",
    "        print(\"--- Epoch {} --- Accuracy AB 1: {} ---\".format(e, acc_ab_2))\n",
    "        #print(\"--- Epoch {} --- Accuracy AB 2: {} ---\".format(e, acc_ab_3))\n",
    "        #print(\"--- Epoch {} --- Accuracy AB 3: {} ---\".format(e, acc_ab_4))\n",
    "        print(\"--- Epoch {} --- Mean Accuracy: {} ---\".format(e, mean_acc))\n",
    "\n",
    "print(\"Final Loss is: {}\".format(loss))\n",
    "print(\"Final Selected genes are: {}\".format(out_i))\n",
    "print(\"Final Selected gene scores are: {}\".format(scores))\n",
    "print(\"Final Excluded gene scores scores are: {}\".format(scores_comp))\n",
    "print(\"Final All gene scores scores are: {}\".format(all_scores))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T15:29:19.728954949Z",
     "start_time": "2023-11-23T15:29:19.373619454Z"
    }
   },
   "id": "298342c86b212d03"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}